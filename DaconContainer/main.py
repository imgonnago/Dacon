#main.py
# main.py (ìµœì¢… ìˆ˜ì •ë³¸)

# main.py (HS4 ì¶”ê°€ ìˆ˜ì •ë³¸)

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score
from data import data_load, data_preparing, find_comovement_pairs, build_training_data, tranfrom_log_minmax
from EDA import EDA_run
from automl import automl1, automl2
from train import predict
from util import baseline


def main():
    train = data_load()
    print(train.head())

    # â˜… 1. (ì‹ ê·œ) HS4 ë§¤í•‘ í…Œì´ë¸” ìƒì„± (data_preparingë³´ë‹¤ ë¨¼ì €!)
    #    'hs4_code'ê°€ train.csvì— ìˆëŠ” ì»¬ëŸ¼ëª…ì´ë¼ê³  ê°€ì •í•©ë‹ˆë‹¤.
    hs_col_name = 'hs4'  # ë§Œì•½ ì»¬ëŸ¼ëª…ì´ ë‹¤ë¥´ë©´ ì´ ë¶€ë¶„ë§Œ ìˆ˜ì •

    if hs_col_name not in train.columns:
        print(f"ì˜¤ë¥˜: train.csvì— '{hs_col_name}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("HS4 í”¼ì²˜ ì—†ì´ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
        item_hs4_map = {}  # ë¹ˆ ë§µ
    else:
        print("HS4 ë§¤í•‘ í…Œì´ë¸” ìƒì„± ì¤‘...")
        # item_idì™€ hs4_codeì˜ ê³ ìœ í•œ ì¡°í•©ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë§Œë“­ë‹ˆë‹¤.
        item_hs4 = train[['item_id', hs_col_name]].drop_duplicates().set_index('item_id')
        item_hs4_map = item_hs4[hs_col_name].to_dict()
        print("HS4 ë§¤í•‘ í…Œì´ë¸” ìƒì„± ì™„ë£Œ.")

    print("=====data preparing=====")
    monthly, pivot_df_value, pivot_df_weight = data_preparing(train)

    # --- 2. í›„ë³´êµ° ìƒì„± ---
    print("=====í›„ë³´ ê³µí–‰ì„±ìŒ íƒìƒ‰ (ë‚®ì€ ì„ê³„ê°’)=====")
    pairs_value = find_comovement_pairs(pivot_df_value, pivot_df_value, corr_threshold=0.0)
    pairs_weight = find_comovement_pairs(pivot_df_weight, pivot_df_value, corr_threshold=0.0)

    # ... (all_pairs ì¤‘ë³µ ì œê±° ë¡œì§ì€ ë™ì¼) ...
    all_pairs_raw = pd.concat([pairs_value, pairs_weight])
    all_pairs_raw['abs_corr'] = all_pairs_raw['max_corr'].abs()
    all_pairs_sorted = all_pairs_raw.sort_values(by='abs_corr', ascending=False)
    all_pairs = all_pairs_sorted.drop_duplicates(
        subset=["leading_item_id", "following_item_id"],
        keep="first"
    )

    # â˜… 3. (ì‹ ê·œ) all_pairsì— HS4 ì •ë³´ ë³‘í•© (merge ëŒ€ì‹  map ì‚¬ìš©)
    if item_hs4_map:  # ë§µì´ ë¹„ì–´ìˆì§€ ì•Šë‹¤ë©´
        print("all_pairsì— HS4 ì •ë³´ ë³‘í•© ì¤‘...")
        all_pairs['leader_hs4'] = all_pairs['leading_item_id'].map(item_hs4_map).fillna('UNKNOWN')
        all_pairs['follower_hs4'] = all_pairs['following_item_id'].map(item_hs4_map).fillna('UNKNOWN')
        print("HS4 ì •ë³´ ë³‘í•© ì™„ë£Œ.")
    else:
        # HS4 ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´, build_training_dataê°€ ì˜¤ë¥˜ë‚˜ì§€ ì•Šë„ë¡ ë¹ˆ ì»¬ëŸ¼ ì¶”ê°€
        all_pairs['leader_hs4'] = 'UNKNOWN'
        all_pairs['follower_hs4'] = 'UNKNOWN'

    # ... (EDA ë¶€ë¶„) ...

    # --- 4. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ---
    # build_training_dataëŠ” HS4 ì •ë³´ê°€ ì¶”ê°€ëœ all_pairsë¥¼ ì „ë‹¬ë°›ìŒ
    print("=====ì „ì²´ í•™ìŠµ ë°ì´í„° ìƒì„± (í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§)=====")
    df_train_all = build_training_data(pivot_df_value, pivot_df_weight, all_pairs)

    # ... (ì´í›„ tranfrom_log_minmax, ë°ì´í„° ë¶„ë¦¬, ëª¨ë¸ í•™ìŠµ, ì„ê³„ê°’ íƒìƒ‰, ì˜ˆì¸¡ ì½”ë“œëŠ”
    #    ì´ì „ì— ì•Œë ¤ë“œë¦° 'main.py (ìµœì¢… ìˆ˜ì •ë³¸)'ê³¼ 'ì™„ì „íˆ ë™ì¼'í•©ë‹ˆë‹¤.) ...

    print("=======ë°ì´í„° ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ=======\n")
    df_train_scaled_all, x_scaler, y_scaler = tranfrom_log_minmax(df_train_all)

    df_train_clf = df_train_scaled_all.copy()
    df_train_clf['target'] = (df_train_all['target'] > 0).astype(int)
    print(df_train_clf['target'].value_counts())

    df_train_reg = df_train_scaled_all[df_train_all['target'] > 0].copy()
    print(f"íšŒê·€(automl2) í•™ìŠµ ë°ì´í„° shape: {df_train_reg.shape}")

    print("\n=======ì„ê³„ê°’ íƒìƒ‰ì„ ìœ„í•œ í›ˆë ¨/ê²€ì¦ ë°ì´í„° ë¶„ë¦¬=======")
    X_clf = df_train_clf.drop(columns=['target'])
    y_clf = df_train_clf['target']

    X_train_for_clf, X_val_for_clf, y_train_for_clf, y_val_for_clf = train_test_split(
        X_clf, y_clf, test_size=0.2, random_state=42, stratify=y_clf
    )

    df_train_for_clf = X_train_for_clf.copy()
    df_train_for_clf['target'] = y_train_for_clf

    print(f"automl1 í›ˆë ¨ ë°ì´í„°: {df_train_for_clf.shape}")
    print(f"ì„ê³„ê°’ ê²€ì¦ ë°ì´í„°: {X_val_for_clf.shape}")

    print("\n=======ëª¨ë¸ 1 (ë¶„ë¥˜ê¸° F1) í•™ìŠµ ì‹œì‘=======")
    model_clf = automl1(df_train_for_clf)
    print("=======ëª¨ë¸ 1 (ë¶„ë¥˜ê¸° F1) í•™ìŠµ ì™„ë£Œ=======\n")

    print("=======ë¶„ë¥˜ê¸°(automl1) ìµœì  ì„ê³„ê°’ íƒìƒ‰ ì‹œì‘=======")
    y_pred_proba = model_clf.predict_proba(X_val_for_clf)[:, 1]

    best_threshold = 0.5
    best_f1 = 0.0
    thresholds = np.arange(0.1, 0.9, 0.05)

    for th in thresholds:
        y_pred_binary = (y_pred_proba > th).astype(int)
        score = f1_score(y_val_for_clf, y_pred_binary)
        print(f"Threshold: {th:.2f}, F1 Score: {score:.6f}")

        if score > best_f1:
            best_f1 = score
            best_threshold = th

    print(f"=======ìµœì  ì„ê³„ê°’ íƒìƒ‰ ì™„ë£Œ=======")
    print(f"â˜… ìµœì  ì„ê³„ê°’: {best_threshold:.2f} (ê²€ì¦ F1: {best_f1:.6f})\n")

    print("=======ëª¨ë¸ 2 (íšŒê·€ MAE) í•™ìŠµ ì‹œì‘=======")
    model_reg = automl2(df_train_reg)
    print("=======ëª¨ë¸ 2 (íšŒê·€ MAE) í•™ìŠµ ì™„ë£Œ=======\n")

    print("=======ì˜ˆì¸¡ ì‹œì‘=======")
    submission = predict(
        pivot_df_value=pivot_df_value,
        pivot_df_weight=pivot_df_weight,
        pairs=all_pairs,
        model_clf=model_clf,
        model_reg=model_reg,
        x_scaler=x_scaler,
        y_scaler=y_scaler,
        optimal_threshold=best_threshold
    )
    print("=======predict complete=======\n")
    print(submission.head())

    baseline(submission)
    print("baseline_submission.csv ìƒì„± ì™„ë£Œ (ê²½ë¡œ: util.pyì— ì§€ì •ëœ ìœ„ì¹˜)")


if __name__ == "__main__":
    print("=======main ì‹œì‘ (2-ëª¨ë¸ + ìµœì  ì„ê³„ê°’ + HS4)=======ğŸ¤\n")
    main()
"""from operator import concat
import pandas as pd
from data import data_load, data_preparing, find_comovement_pairs, build_training_data, tranfrom_log_minmax
from EDA import EDA_run
from automl import automl
from model import model
from train import predict, fit
from util import baseline


def main():
    train = data_load()
    print(train.head())
    print("=====data preparing=====")
    monthly,pivot_df_value, pivot_df_weight = data_preparing(train)
    pairs_value = find_comovement_pairs(pivot_df_value,pivot_df_value)
    pairs_weight = find_comovement_pairs(pivot_df_weight,pivot_df_value)
    all_pairs = pd.concat([pairs_value, pairs_weight])

    answer = input("EDAë¥¼ ì§„í–‰í• ê¹Œìš”? (y/n) >>")
    if answer == "y":
        EDA_run(train)
    elif answer == "n":
        print("EDAë¥¼ ê±´ë„ˆëœ€\n")

    print("íƒìƒ‰ëœ ê³µí–‰ì„±ìŒ ìˆ˜:", len(pairs_value) + len(pairs_weight))
    print("-------pairs_value-------")
    print(pairs_value.head())
    print("-------pairs_weight-------")
    print(pairs_weight.head())
    print("-------add_pairs-------")
    print(pairs_value.head())
    print("\n")

    df_train = build_training_data(pivot_df_value, pivot_df_weight, all_pairs)
    df_train, x_scaler, y_scaler = tranfrom_log_minmax(df_train)
    print(df_train)
    print("=======train_x,y split complete=======\n")
    hard_voting_model = automl(df_train)
    #hard_voting_model = model()
    #fit(hard_voting_model,df_train)
    print("=======voting model fit complete=======\n")
    submission = predict(pivot_df_value,pivot_df_weight, all_pairs, hard_voting_model,x_scaler,y_scaler)
    print("=======predict complete=======\n")
    submission.head()

    baseline(submission)
    if answer == "m":
        print("baseline_submission ìƒì„±ì™„ë£Œ (Dacon/baselinez)")
    elif answer == "w":
        print("baseline_submission ìƒì„±ì™„ë£Œ (Dacon/baseline)")
    elif answer == 1:
        print("baseline_submission ìƒì„±ì‹¤íŒ¨")


if __name__ == "__main__":
    print("=======main ì‹œì‘=======ğŸ¤\n")
    main()"""
